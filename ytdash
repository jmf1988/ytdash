#!/usr/bin/python3
# -*- coding: utf-8 -*-


class Writer:
    def __init__(self, file):
        self.file = file

    def write(self, data):
        # sys.stderr.write(data)
        if player.poll() is not None:
            # fd.close()
            return 0
        try:
            self.file.write(data)
        except BrokenPipeError:
            return 0


class Endit(Exception):
    pass


def time_type(string):
    if not re.match(r"^[0-9]+[HhMmSs]$|^$", string):
        raise argparse.ArgumentTypeError
    return string


def dict_from_bytes(byteheaders):
    headers = {}
    byteheaders.seek(0)
    listheaders = byteheaders.read().decode('iso-8859-1').split('\r\n')
    for header in listheaders:
        if re.match(r'.*: .*', header):
            header = header.split(': ')
            headers[header[0]] = header[1]
    return headers


def log_(infos):
    logging.debug('''--->Going %s, to VID: %s
                         REMAINING SEGMENTS: %s
                         MIN DELAY: %s
                         FFMUX DELAY: %s
                         DELAY TO UP: %s
                         TRUE DELAYS: %s
                         TRUE DELAY AVG: %s
                         BASE DELAYS: %s
                         BASE DELAY AVG: %s
                         DELAYS: %s
                         DELAY AVG: %s
                         CURRENT BAND: %s
                         NEXT BAND: %s
                         NEW VIDEO URL: %s''' % infos)


def download(curlobj, url, compressed=0, rangebytes=(0, ''), bytesresponse=0,
             api=0):
    retries = 3
    status = response = message = 0
    curlobj.setopt(pycurl.URL, url)
    if compressed:
        curlobj.setopt(pycurl.ACCEPT_ENCODING, '')
    if (type(rangebytes) is tuple and len(rangebytes) == 2 and
       rangebytes != (0, '') and rangebytes[1] > rangebytes[0]+1):
            bytesresponse = 1
            curlobj.setopt(pycurl.RANGE, '%s-%s' % rangebytes)
    while retries:
        try:
            if bytesresponse:
                response = curlobj.perform_rb()
            else:
                response = curlobj.perform_rs()
            status = curlobj.getinfo(pycurl.RESPONSE_CODE)
            curlerrnum = 0
            if status != 200 and status != 206 and status != 403:
                retries -= 1
                time.sleep(1)
                continue
            break
        except pycurl.error as error:
            curlerrnum = error.args[0]
            retries -= 1
            time.sleep(1)
    # if compressed:
    curlobj.setopt(pycurl.ACCEPT_ENCODING, None)
    # if rangebytes and rangebytes != (0, ''):
    curlobj.setopt(pycurl.RANGE, None)
    if retries < 1:
        if curlerrnum == 6:
            message = 'Could not resolve host. Internet connection issues?'
        else:
            message = ('Retries exhausted trying to open URL: ' + url +
                       '\nCURL Error: ' + str(curlerrnum))
    if status and status != 200 and status != 206:
        message = 'Http Error %s trying to obtain critical info.' % status
        if not api:
            response = 0
    if message:
        logging.fatal(message)
        notify_send(message)
    return response


def get_mediadata(curlobj, videoid, test=1, checkiflive=0):
    # https://www.youtube.com/oembed?url=[Youtubewatchurl]&format=json
    # New api to get the data but with Unknown key
    url = 'https://www.youtube.com/youtubei/v1/player?key=' + 'AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8'
    curlobj.setopt(pycurl.HTTPHEADER, ['Content-Type: application/json'])
    curlobj.setopt(pycurl.POST, 1)
    curlobj.setopt(pycurl.ENCODING, 'gzip, deflate')
    postdata =  {"context": {"client": {"hl": "en", "clientName": "WEB",
                                        "clientVersion": "2.20210721.00.00",
                                        "mainAppWebInfo": {
                                                "graftUrl": "/watch?v=" + videoid
                                               }
                                        }
                            },
                "videoId": videoid
                }
    curlobj.setopt(curlobj.POSTFIELDS, json.dumps(postdata))
    logging.debug('Opening URL: %s ' % url)
    res = download(curlobj, url)
    curlobj.setopt(pycurl.HTTPHEADER, None)
    curlobj.setopt(pycurl.POST, 0)
    if not res:
        logging.info('Could not get video basic information...')
        return 2
    ytdict = json.loads(res)
    if ytdict:
        metadata = {}
        otf = False
        streamtype = ytdict.get('qoe_cat')
        if streamtype:
            otf = True
        metadata['Otf'] = otf
        logging.debug('stream type: ' + str(streamtype))
    else:
        logging.debug('Could not get main dictionary...')
        return 2
    ytpresp = ytdict
    if ytpresp:
        #ytpresp = json.loads(ytpresp[0])
        playable = ytpresp.get('playabilityStatus')
        pstatus = playable.get('status')
        reason = playable.get('reason')
        metadata['reason'] = reason
        if pstatus and pstatus == 'UNPLAYABLE':
            logging.info('Video status: UNPLAYABLE')
            if reason:
                href = re.findall(r'(?<=href=").*?(?=")', reason)
                if href:
                    reco = re.findall(r'(?<=>).*?(?=<)', reason)
                    if reco:
                        reco = reco[0] + ' --> ' + href[0]
                        realreason = re.findall(r'(?<=\n).*$', reason)
                        if realreason:
                            reason = realreason[0] + '\n' + reco
                logging.info("Reason: %s" % reason)
            return 2
    else:
        logging.debug('Could not extract player response data...')
        return 2
    liveaheadsecs = ytdict.get('live_readahead_seconds')
    liveaheadchunk = ytdict.get('live_chunk_readahead')
    latencyclass = ytdict.get('latency_class')
    livestream = ytdict.get('livestream')
    liveplayback = ytdict.get('live_playback')
    ytpconfig = ytpresp.get('playerConfig')
    if ytpconfig:
        audioconfig = ytpconfig.get('audioConfig')
        streamconfig = ytpconfig.get('streamSelectionConfig')
        if streamconfig:
            maxbitrate = streamconfig.get('maxBitrate')
            logging.debug('MaxBitrate: ' + maxbitrate)
    # Get Video Details:
    videodetails = ytpresp.get('videoDetails')
    if videodetails:
        metadata.update(videodetails)
        # print('Metadata: ' + str(metadata))
        title = videodetails.get('title')
        description = videodetails.get('shortDescription')
        author = videodetails.get('author')
        isprivate = videodetails.get('isPrivate')
        viewcount = videodetails.get('viewCount')
        lengthsecs = videodetails['lengthSeconds']
        postlivedvr = videodetails.get('isPostLiveDvr')
        livecontent = videodetails.get('isLiveContent')
        live = videodetails.get('isLive', False)
        lowlatency = videodetails.get('isLowLatencyLiveStream')
        livedvr = videodetails.get('isLiveDvrEnabled')
    else:
        logging.debug('No video details data found...')
        return 2
    # If only checking live status return quickly:
    if checkiflive:
        return (live, reason)
    # Get streaming Data:
    streamingdata = ytpresp.get('streamingData')
    if streamingdata:
        dashmanurl = streamingdata.get('dashManifestUrl')
        hlsmanurl = streamingdata.get('hlsManifestUrl')
        manifesturl = dashmanurl
        metadata['ManifestUrl'] = manifesturl
        formats = streamingdata.get('formats')
        adaptivefmts = streamingdata.get('adaptiveFormats')
        if adaptivefmts:
            # logging.debug('ADAPTIVEFMTS: ' + str(adaptivefmts))
            adaptivefmts.sort(key=lambda fmt: fmt.get('bitrate', 0))
            nomanaudiodata = []
            nomanvideodata = []
            for fid in range(len(adaptivefmts)):
                mtype = adaptivefmts[fid]['mimeType'].split('; ')
                if mtype[0] == 'audio/mp4' and mtype[1][8:11] == 'mp4':
                    nomanaudiodata.append(adaptivefmts[fid])
                elif mtype[0] == 'video/mp4' and mtype[1][8:11] == 'avc':
                    streamtype = adaptivefmts[fid].get('type')
                    if streamtype != 'FORMAT_STREAM_TYPE_OTF':
                        nomanvideodata.append(adaptivefmts[fid])
                    else:
                        otf = True
            # logging.debug('Videodata: %s' % nomanvideodata)
            if streamtype == 'FORMAT_STREAM_TYPE_OTF':
                otf = True
            metadata['Otf'] = otf
        logging.debug('OTF: ' + str(otf))
    else:
        manifesturl = None
        logging.debug('No streaming data found...')
        return 2
    if not latencyclass:
        latencyclass = videodetails.get('latencyClass')
        if latencyclass:
            latencyclass = re.findall('(?<=LATENCY_).+', latencyclass)
            metadata['latencyClass'] = latencyclass[0]
    if adaptivefmts and (not livecontent or not manifesturl or otf):
        audiodata = nomanaudiodata
        videodata = nomanvideodata
        cipher = 0
        nourls = 0
        if not audiodata[-1].get('url') or not videodata[-1].get('url'):
            logging.debug('Media Urls could not be found.')
            nourls = 1
            if audiodata[-1].get('cipher') or videodata[-1].get('cipher'):
                logging.debug('Ciphered url/s.')
                cipher = 1
        if nourls or cipher:
            return 2
    # logging Details:
    logging.debug("Is live: %s" % live)
    logging.debug('postLiveDVR: ' + str(postlivedvr))
    logging.debug('reason: ' + str(reason))
    logging.debug('liveplayback: ' + str(liveplayback))
    logging.debug('livestream: ' + str(livestream))
    logging.debug('title: ' + str(title))
    logging.debug('description: ' + str(description))
    logging.debug('isprivate: ' + str(isprivate))
    logging.debug('islive: ' + str(live))
    logging.debug('islivecontent: ' + str(livecontent))
    logging.debug('islowlatency: ' + str(lowlatency))
    logging.debug('islivedvr: ' + str(livedvr))
    logging.debug('latencyclass: ' + str(latencyclass))
    logging.debug('live readahead secs: ' + str(liveaheadsecs))
    logging.debug('live readahead chunks: ' + str(liveaheadchunk))
    # Abort if live videos were requested, and video is not:
    if not live and not args.nonlive:
        if livecontent:
            logging.info('This video stream is no longer live.')
        else:
            logging.info('This video is not live content.')
        logging.info('Pass -nonlive/-nl option to enable non-live videos.')
        return 1
    # Getting media urls from manifest if available except for OTF type:
    if manifesturl and not otf:
        # Otf's Manifest is organized differently:
        if otf:
            if not lowlatency:
                segsecs = 5
            ida = 0
            idv = 1
        else:
            ida = 1
            idv = 2
        fps_string = 'frameRate'
        manifesturl += '/keepalive/yes'
        logging.debug("Manifest URL: %s" % manifesturl)
        # Get the Manifest data, compression enabled:
        stime = time.time()
        rawmanifest = download(curlobj, manifesturl, 1)
        logging.debug('Manifest download time: ' + str(time.time() - stime))
        if not rawmanifest:
            logging.info("Unable to obtain manifest content...")
            return 2
        # MPD manifest parsing:
        MPD = ET.fromstring(rawmanifest)
        del rawmanifest
        Period = MPD[0]
        SegmentList = Period[0]
        # Duration list per each segment:
        SegmentTimeline = SegmentList[0]
        # There's an Adaptation Set per format (mimeType/codec) and media type,
        # Filter out non-mp4 formats becuase do not work yet:
        AdaptationSets = Period[1:]
        for AdaptationSet in AdaptationSets:
            if AdaptationSet.get('mimeType') == 'audio/mp4':
                AdaptationSetAudio = AdaptationSet
            elif AdaptationSet.get('mimeType') == 'video/mp4':
                AdaptationSetVideo = AdaptationSet
        AudioRole = AdaptationSetAudio[0]
        VideoRole = AdaptationSetVideo[0]
        # All media qualities for the set codec:
        AudioRepresentations = AdaptationSetAudio[1:]
        VideoRepresentations = AdaptationSetVideo[1:]
        # Get some info from mpd key's attributes:
        startnumber = int(SegmentList.attrib.get('startNumber', 0))
        presentationTimeOffset = int(SegmentList.get('presentationTimeOffset',
                                                     0))
        periodstarttime = Period.get('start')
        if periodstarttime:
            periodstarttime = int(float(periodstarttime[2:-1]))
            metadata['start'] = periodstarttime
        earliestseqnum = int(MPD.get('{http://youtube.com/yt/2012/10/10}' +
                                     'earliestMediaSequence', 0))
        timescale = float(SegmentList.get('timescale', 0))
        buffersecs = MPD.get('timeShiftBufferDepth')
        if buffersecs:
            buffersecs = float(buffersecs[2:-1])
        minuperiod = Period.get('minimumUpdatePeriod')
        if minuperiod:
            segsecs = int(minuperiod[2:-1])
        elif timescale:
            segsecs = round(float(SegmentTimeline[0].get('d')) / timescale)
        metadata['segmentsnumber'] = len(SegmentTimeline)
        # Media Metadata:
        audiodata = AudioRepresentations
        videodata = VideoRepresentations
        # Sort Audio and Video qualities by bandwidth:
        for mtype in audiodata, videodata:
            mtype.sort(key=lambda mid: int(mid.attrib.get('bandwidth', 0)))
        if not otf:
            testurl = audiodata[0][1].text
    else:
        logging.debug('Dash Manifest URL not available.')
        logging.info('Bandwidth adaptative mode not available.')
        if adaptivefmts:
            testurl = audiodata[0].get('url')
            logging.debug('Manifestless adaptative formats available.')
            fps_string = 'fps'
            segsecs = 5
            buffersecs, earliestseqnum, startnumber = 0, 0, 0
        else:
            logging.debug('No adaptative video formats found.')
            return 2
    totvqua = len(videodata)
    # Filter video by max height, width, fps and bandwidth:
    idx = 0
    while idx < len(videodata):
        # logging.info(videodata[idx].get('bandwidth'))
        videofps = int(videodata[idx].get(fps_string, 0))
        videoheight = int(videodata[idx].get('height', 0))
        videowidth = int(videodata[idx].get('width', 0))
        if livecontent and manifesturl and not otf:
            videoband = int(videodata[idx].attrib.get('bandwidth', 0))
        else:
            videoband = 0
        if(videofps > args.maxfps or videoheight > maxheight
           or videowidth > maxwidth or
           videoband / 8 > args.maxband * 1024):
            del videodata[idx]
        else:
            idx += 1
    if len(videodata) < 1:
        logging.info('No video found with the requested properties.')
        return 2
    logging.info("Video qualities selected: %s/%s" % (len(videodata), totvqua))
    logging.info("Audio qualities selected: %s/%s" % ('1', len(audiodata)))
    # Test for url health:
    if test:
        if postlivedvr:
            testurl = testurl + 'sq/' + str(earliestseqnum + 3)
        logging.debug('Testing URL: ' + testurl)
        curlobj.setopt(curlobj.URL, testurl)
        testresp = download(curlobj, testurl, 0, (0, 1024))
        if not testresp:
            logging.info("Error testing URL, aborting...")
            return 2
        else:
            logging.debug("The URL seems healthy.")
    return (latencyclass, audiodata, videodata, buffersecs, earliestseqnum,
            startnumber, metadata, segsecs)


def ffmuxer(ffmpegbin, ffmuxerstdout, apipe, vpipe):
    ffmpegargs = '%s -y -v %s -nostdin ' % (ffmpegbin, ffloglevel)
    ffmpegargsinputs = ' -thread_queue_size 512 -flags +low_delay '
    if apipe:
        ffmpegargs += ffmpegargsinputs + '-i async:pipe:%s ' % apipe
        fds = (apipe, vpipe)
    else:
        fds = (vpipe,)
    ffmpegargs += ffmpegargsinputs + ' -i async:pipe:%s ' % vpipe
    ffmpegargs += '-f mpegts -bsf:v h264_mp4toannexb -c copy -copyts '
    ffmpegargs += '-flags +low_delay -'
    ffmpegmuxer = subprocess.Popen(shlex.split(ffmpegargs),
                                   bufsize=-1,
                                   stdout=ffmuxerstdout,
                                   stderr=None,
                                   close_fds=True,
                                   pass_fds=fds)
    fftries = 0
    while ffmpegmuxer.poll() is not None:
        print("Waiting ffmpeg muxer...")
        if fftries < 15:
            time.sleep(1)
        else:
            raise Exception
        fftries += 1
    return ffmpegmuxer


def notify_send(message, duration=10000, title='YTdash'):
    try:
        subprocess.call(['notify-send', title, message, '-t', str(duration)])
    except:
        pass


def get_media(data):
    baseurl, segmenturl, fd, curlobj, init = data
    errxxxr = err4xxr = 3  # Max retries when http errors.
    interruptretries = -1  # Infinite retry
    curlerr18retries = 2  # Happens sometimes when streaming ends
    twbytes = 0
    totallength = 0
    newurl = None
    initbyte = 0
    interrupted = error = 0
    ended = False
    reason = None
    if not livecontent or not manifesturl:
        curlobj.setopt(pycurl.TIMEOUT, 120)
        maxbytes = 524288
        curlobj.setopt(pycurl.RANGE, '%s-%s' % (initbyte, initbyte + maxbytes))
    else:
        maxbytes = 0
    while True:
        url = baseurl + segmenturl
        rawheaders = BytesIO()
        try:
            if twbytes:
                sbyte = initbyte + int(twbytes)
                if maxbytes:
                    ebyte = sbyte + maxbytes
                    if totallength and ebyte > totallength:
                        ebyte = totallength
                else:
                    ebyte = ''
                curlobj.setopt(pycurl.RANGE, '%s-%s' % (sbyte, ebyte))
                logging.debug("Trying to resume from byte: %s to %s" % (sbyte,
                                                                        ebyte))
            curlobj.setopt(pycurl.URL, url)
            curlobj.setopt(curlobj.HEADERFUNCTION, rawheaders.write)
            if init != 1:
                # Write media content to ffmpeg or player pipes:
                if otf and not twbytes and init:
                    iwbytes = fd.write(init)
                curlobj.setopt(pycurl.NOBODY, 0)
                curlobj.setopt(pycurl.HEADER, 0)
                # curlobj.setopt(pycurl.WRITEDATA, fd)
                curlobj.setopt(pycurl.WRITEFUNCTION, Writer(fd).write)
            else:
                curlobj.setopt(pycurl.NOBODY, 1)
            logging.debug("Getting Media Content.....")
            # curlobj.setopt(pycurl.WRITEFUNCTION,
            #                   lambda data:  onrecv(fd, data) )
            if player.poll() is not None:
                return 1
            curlobj.perform()
            if interrupted:
                curlobj.setopt(pycurl.RANGE, None)
                interrupted = 0
            logging.debug("Saving content to: " + str(fd))
            # fd.write(content)
        except (BrokenPipeError, OSError) as oserr:
            logging.debug("Exception Ocurred: %s %s" % (oserr, str(oserr.args)))
            return 1
        except pycurl.error as err:
            logging.debug("Pycurl Exception Ocurred: %s Args: %s" %
                          (err, str(err.args)))
            curlerrnum = err.args[0]
            error = 1
            rawheaders.close()
            if curlerrnum == 18:
                logging.debug('Server closed connection with unknown' +
                              ' data remaining...')
                # (18, 'transfer closed with outstanding read data remaining')
                if not curlerr18retries:
                    logging.debug("Curl error 18 retries exhausted, aborting.")
                    fd.close()
                    return 1
                curlerr18retries -= 1
                interrupted = 1
                time.sleep(1)
            elif curlerrnum == 23:
                logging.debug("Write error and player closed, quitting...")
                fd.close()
                return 1
            # Curlerror 28 is connection timeout, enables download resume:
            elif(curlerrnum == 7 or curlerrnum == 56 or curlerrnum == 28 or
                 curlerrnum == 52):
                    logging.debug('Download interrupted.')
                    if not interruptretries:
                        logging.info("Retries after interruption exhausted, " +
                                     "aborting...")
                        fd.close()
                        return 1
                    interruptretries -= 1
                    interrupted = 1
                    time.sleep(1)
            elif curlerrnum == 6:
                print(' ' * columns, end='\r')
                messa = ('Could not resolve host. Internet connection issues?')
                print(messa, end='\r')
                time.sleep(5)
                notify_send(messa, 5000)
                continue
            else:
                logging.info("No handled pycurl error number, please report" +
                             " it, aborting...")
                fd.close()
                return 1
        twbytes += int(curlobj.getinfo(pycurl.SIZE_DOWNLOAD))
        if interrupted:
            if twbytes:
                logging.debug("Partial download, size: " + str(twbytes))
            continue
        basedelay = curlobj.getinfo(pycurl.APPCONNECT_TIME)
        # Getting metadata from headers:
        headers = dict_from_bytes(rawheaders)
        headnumber = int(headers.get('X-Head-Seqnum', 0))
        sequencenum = int(headers.get('X-Sequence-Num', 0))
        headtime = int(headers.get('X-Head-Time-Sec', 0))
        walltimems = int(headers.get('X-Walltime-Ms', 0))
        if not totallength:
            totallength = headers.get('Content-Range', '').split('/')[-1]
            if totallength:
                if totallength != '*':
                    totallength = int(totallength)
                else:
                    totallength = ''
        contentlength = int(headers.get('Content-Length', 0))
        acceptranges = headers.get('Accept-Ranges', 0)
        cachecontrol = headers.get('Cache-Control', 0)
        headtimems = int(headers.get('X-Head-Time-Millis', 0))
        segmentlmt = int(headers.get('X-Segment-Lmt', 0))
        contenttype = headers.get('Content-Type', 0)
        speed = curlobj.getinfo(pycurl.SPEED_DOWNLOAD)
        totaltime = curlobj.getinfo(pycurl.TOTAL_TIME)
        conntime = curlobj.getinfo(pycurl.CONNECT_TIME)
        if contenttype == 'video/mp4':
            bandwidthavg = int(int(headers.get('X-Bandwidth-Avg', 0))/1024)
            bandwidthest = int(int(headers.get('X-Bandwidth-Est', 0))/1024)
            bandwidthest2 = int(int(headers.get('X-Bandwidth-Est2', 0))/1024)
            bandwidthest3 = int(int(headers.get('X-Bandwidth-Est3', 0))/1024)
            bandwidths = [bandwidthavg, bandwidthest, bandwidthest2,
                          bandwidthest3]
        else:
            bandwidths = 0
        status = curlobj.getinfo(pycurl.RESPONSE_CODE)
        # Check status codes:
        if status == 200 or status == 206:
            errxxxr = err4xxr = 3
            # redirurl = curlobj.getinfo(pycurl.REDIRECT_URL)
            lasturl = curlobj.getinfo(pycurl.EFFECTIVE_URL)
            if not url == lasturl:
                rurl = lasturl + "/"
                if segmenturl:
                    baseurl = newurl = rurl.replace(segmenturl + "/", '')
                elif not livecontent:
                    baseurl = rurl[0:-1]
                if newurl:
                    logging.debug('Saving new url: %s' % newurl)
            if totallength and twbytes < totallength:
                continue
            else:
                # All live and non-live non-otf close fds:
                if not (otf and contenttype == 'audio/mp4'):
                    rawheaders.close()
                    fd.close()
                # Non-live manifestless directly end it:
                if not manifesturl:
                    return 1
            info = (status, basedelay, headnumber, headtimems, sequencenum,
                    walltimems, segmentlmt, contentlength, cachecontrol,
                    bandwidths, speed, contenttype, newurl, error)
            logging.debug('Bytes written: %s' % twbytes)
            return info
        else:
            logging.debug('HTTP error status code: %s' % status)
            logging.debug("Request's URL: " + url)
            error = 1
            # In some live videos a segment may not be available yet:
            if(live and (status == 404 or status == 204) and segmenturl and
               type(segmenturl) is str and (int(segmenturl[3:]) > headnumber or
               not sequencenum) and err4xxr > 1):
                    logging.debug('Segment not available yet.')
                    logging.debug('Retrying in 1 second')
                    err4xxr -= 1
                    time.sleep(max(segsecs/2, 1))
            else:
                # For all http errors refresh data and retry errxxxr times:
                time.sleep(segsecs)
                # Error 503 is less recoverable it seems, so less retries:
                if status == 503:
                    logging.info('Service unavailable error...')
                    errxxxr -= 2
                if live:
                    logging.debug('Refreshing video metadata...')
                    curlobj.setopt(pycurl.WRITEDATA, sys.stdout)
                    livecheck = get_mediadata(curlobj, videoid, 0, 1)
                    if type(livecheck) is int:
                        if livecheck == 2:
                            logging.info("Error refreshing metadata.")
                            errxxxr = 0
                    elif type(livecheck) is tuple:
                        islive, reason = livecheck[0], livecheck[1]
                        if not islive:
                            ended = True
                        elif reason:
                            if reason == 'Offline.':
                                ended = True
                            else:
                                logging.info("Youtube's reason: " + reason)
                        else:
                            logging.debug("Event is still live...")
                    if ended:
                        logging.debug("Live event ended.")
                errxxxr -= 1
            # If retries exhausted or Youtube give a reason of failure, quit:
            if err4xxr < 1 or errxxxr < 1 or reason or ended:
                rawheaders.close()
                fd.close()
            if ended:
                return 4
            elif err4xxr < 1 or errxxxr < 1:
                return 2
            elif reason:
                return 3


def closepipes(totalpipes):
    pipes = []
    t = type(totalpipes)
    if t is list or t is tuple:
        for segmenttuples in totalpipes:
            t = type(segmenttuples)
            if t is list or t is tuple:
                for pipetuple in segmenttuples:
                    t = type(pipetuple)
                    if t is list or t is tuple:
                        for fd in pipetuple:
                            if type(fd) is int:
                                pipes.append(fd)
                            else:
                                logging.debug('closepipes limit reached.')
                    elif t is int:
                        pipes.append(pipetuple)
            elif t is int:
                pipes.append(segmenttuples)
    elif t is int:
        pipes.append(totalpipes)
    for pipe in pipes:
        try:
            if pipe > 2:
                logging.debug('Closing pipe: %s' % pipe)
                os.close(pipe)
        except OSError:
            pass


if __name__ == '__main__':
    import sys
    import os
    # Disable non-blocking mode on stdin to avoid EOFError with input(), and
    # potential security implications:
    os.set_blocking(sys.stdin.fileno(), True)
    import argparse
    import re
    parser = argparse.ArgumentParser(prog='ytdash',
                                     description='Youtube DASH video playback.')
    parser.add_argument('urls', metavar='URL|QUERY', type=str, nargs='+',
                        help='URLs or search queries of videos to play')
    parser.add_argument('--version', action='version',
                        version='%(prog)s 0.19-beta')
    parser.add_argument('-quiet', '-q', action='store_true',
                        help='enable quiet mode (default: %(default)s)')
    parser.add_argument('-onlyone', '-oo', action='store_true',
                        help='Only one instance of ytdash can be running. ' +
                        '(default: %(default)s)')
    parser.add_argument('-kill', '-k', action='store_true',
                        help='First terminate all other running instances of ' +
                        'ytdash. (default: %(default)s)')
    parser.add_argument('-search', '-s', action='store_true',
                        help='search mode, results cache enabled if searched' +
                        ' less than 24hs ago, which saves YouTube daily' +
                        ' quota, recommended) (default: %(default)s)')
    parser.add_argument('-research', '-rs', action='store_true',
                        help='Search with cached results disabled.' +
                        ' (default: %(default)s)')
    parser.add_argument('-nonlive', '-nl', action='store_true',
                        help='search also for non-live videos ' +
                        '(default: %(default)s)')
    parser.add_argument('-sortby', '-sb', type=str, default='relevance',
                        choices=['relevance', 'viewCount', 'videoCount', 'date',
                                 'rating', 'title', 'rating'],
                        help='sorting order for the search results ' +
                        '(default: %(default)s)')
    parser.add_argument('-eventtype', '-et', type=str, default='live',
                        choices=['live', 'upcoming', 'completed'],
                        help='filter results by live event type' +
                        '(default: %(default)s)')
    parser.add_argument('-safesearch', '-ss', type=str, default='moderate',
                        choices=['moderate', 'none', 'strict'],
                        help='Safe search mode to use if any' +
                        '(default: %(default)s)')
    parser.add_argument('-duration', '-dur', type=str, default='any',
                        choices=['any', 'long', 'medium', 'short'],
                        help='filter results by video duration' +
                        '(default: %(default)s)')
    parser.add_argument('-videotype', '-vt', type=str, default='any',
                        choices=['any', 'episode', 'movie'],
                        help='filter results by video type ' +
                        '(default: %(default)s)')
    parser.add_argument('-type', type=str, default='video',
                        choices=['video', 'channel', 'playlist'],
                        help='filter results by type of resource ' +
                        '(default: %(default)s)')
    parser.add_argument('-definition', '-vd', type=str, default='any',
                        choices=['hd', 'sd', 'any'],
                        help='filter results by video definition ' +
                        '(default: %(default)s)')
    parser.add_argument('-license', type=str, default='any',
                        choices=['creativeCommon', 'youtube', 'any'],
                        help='filter results by video livense type ' +
                        '(default: %(default)s)')
    parser.add_argument('-playlist', '-pl', action='store_true',
                        help='Play all urls/ids found in file(s) ' +
                        '(default: %(default)s)')
    parser.add_argument('-fullscreen', '-fs', action='store_true',
                        help='Start all videos in fullscreen mode ' +
                        '(default: %(default)s)')
    parser.add_argument('-maxresults', '-mr', type=int, default=5,
                        help='search max results (default: %(default)s)')
    parser.add_argument('-debug', '-d', action='store_true',
                        help='enable debug mode  (default: %(default)s)')
    parser.add_argument('-player', '-p', type=str, default='mpv',
                        help='player bin name, (default: %(default)s)')
    parser.add_argument('-nodescription', '-nd', action='store_true',
                        help='Do not show video descriptions on the '
                        'terminal/player (default: %(default)s)')
    parser.add_argument('-volnor', '-vn', action='store_true',
                        help='enable volume normalization ' +
                        ' for all videos (mpv). (default: %(default)s)')
    parser.add_argument('-maxfps', '-mf', type=int, default=60,
                        help='max video fps to allow (default: %(default)s)')
    parser.add_argument('-maxband', '-mb', type=int, default=10000000,
                        help='max video bandwidth in kB/s to allow when ' +
                        ' possible (default: %(default)s)')
    parser.add_argument('-maxheight', '-mh', type=int, default=None,
                        help='maximum video height to allow')
    parser.add_argument('-maxwidth', '-mw', type=int, default=None,
                        help='maximum video width to allow ')
    parser.add_argument('-audioquality', '-aq', type=int, default=1,
                        choices=[0, 1, -1],
                        help='Audio quality to enable if available' +
                        ', 0=lowest, 1=medium, -1=highest. ' +
                        '(default: %(default)s)')
    parser.add_argument('-ffmpeg', '-ff', type=str, default='ffmpeg',
                        help='ffmpeg location route (default: %(default)s)')
    parser.add_argument('-autoplay', '-a', action='store_true',
                        help='Autoplay all results returned by search mode ' +
                        '(default: %(default)s)')
    parser.add_argument('-reallive', '-r', action='store_true',
                        help='Enables lowest latency possible with ' +
                        'all types of live streams. ' +
                        '(default: %(default)s)')
    parser.add_argument('-preferquality', '-pq', action='store_true',
                        help='Prioritize quality over latency in ' +
                        'bandwidth-adaptive enabled video streams ' +
                        '(default: %(default)s)')
    parser.add_argument('-fixed', '-f', action='store_true',
                        help='Play a fixed video quality instead of doing' +
                        ' bandwidth adaptive quality change, This is the max' +
                        ' set from options (default: %(default)s)')
    parser.add_argument('-offset', '-o', type=time_type, default='',
                        help='Time offset from where the playback start,' +
                        '(i.e: -o 2h, -o 210m, -offset 3000s, for hours,' +
                        ' minutes and seconds respectively.) ' +
                        '(default: 3 segments)')
    global args
    args = parser.parse_args()
    import subprocess
    # Check platform and versions needed:
    message = 0
    if sys.platform != 'linux':
        message = "This script runs on Linux only."
    elif sys.version_info[0:2] < (3, 5):
        message = 'Python version 3.5 or higher is needed.'
    else:
        try:
            import pycurl
        except Exception as Exc:
            message = 'Exception occurred while importing pycurl: ' + str(Exc)
        else:
            if pycurl.version.split()[0].split('/')[-1] < '7.43.0.2':
                message = 'PycURL version 7.43.0.2 or higher is needed.'
            else:
                # Check player:
                try:
                    playerccmd = [args.player]
                    if args.player[:3] == 'mpv' or args.player[:3] == 'vlc':
                        playerccmd.append('--version')
                    elif args.player[:6] == 'ffplay':
                        playerccmd.append('-version')
                    playeroutput = str(subprocess.check_output(playerccmd))
                    playeroutput = playeroutput.split()
                except FileNotFoundError:
                    message = args.player + ' player not found.'
                except Exception as Exc:
                    message = 'Exception checking player version: ' + str(Exc)
                else:
                    if args.player[-3:] == 'mpv':
                        if playeroutput and len(playeroutput) > 1:
                            playerver = playeroutput[1]
                            if playerver < '0.28':
                                message = 'Mpv version 0.28 or higher needed.'
                        else:
                            print('Unable to verify the mpv player version.')
                    else:
                        print('*** Ytdash was not tested using this player,' +
                              ' unexpected behaviour and/or errors may happen. '
                              'Please use the recommended player (Mpv>=0.28).')
                if not message:
                    # Check ffmpeg:
                    try:
                        ffmpegver = str(subprocess.check_output([args.ffmpeg,
                                                                 '-version']))
                        ffmpegver = ffmpegver.split()
                    except FileNotFoundError:
                        message = 'FFmpeg not found.'
                    except Exception as Exc:
                        message = 'Exception checking ffmpeg: ' + str(Exc)
                    else:
                        if ffmpegver and len(ffmpegver) > 2:
                            ffmpegver = ffmpegver[2]
                            if ffmpegver < '3.2':
                                message = 'FFmpeg version 3.2 or higher needed.'
                        else:
                            print('Unable to verify the ffmpeg version.')
    if message:
        print(message)
        quit()
    from concurrent.futures import ThreadPoolExecutor, TimeoutError
    from threading import active_count as active_threads
    try:
        import xml.etree.cElementTree as ET
    except ImportError:
        import xml.etree.ElementTree as ET
    from urllib.parse import parse_qs, urlparse, urlencode
    from logging.handlers import logging, RotatingFileHandler
    from io import BytesIO
    import certifi
    import signal
    import time
    import shlex
    import json
    import html
    global ffmpegmuxer, livecontent, live, otf, manifesturl, segsecs, columns
    os.setpgrp()
    # Check directories used:
    homedir = os.environ['HOME']
    cachedir = homedir + '/.cache/ytdash/'
    if not os.path.isdir(cachedir):
        os.mkdir(cachedir)
    # Files to use:
    thispid = os.getpgrp()
    logfile = homedir + '/.ytdash.log'
    # Logging:
    if args.debug:
        loglevel = logging.DEBUG
        ffloglevel = 'warning'
    elif args.quiet:
        loglevel = logging.WARN
        ffloglevel = 'fatal'
    else:
        loglevel = logging.INFO
        ffloglevel = 'fatal'
    # Set logging configs:
    formatter = logging.Formatter('%(asctime)s %(levelname)s %(funcName)' +
                                  's(%(lineno)d) %(message)s')
    handler = RotatingFileHandler(logfile, mode='a+', maxBytes=5*1024*1024,
                                  backupCount=2)
    handler.setFormatter(formatter)
    handler.setLevel(loglevel)
    log = logging.getLogger('')
    log.setLevel(loglevel)
    log.addHandler(handler)
    # Set console loglevel:
    console = logging.StreamHandler()
    console.setLevel(loglevel)
    logging.getLogger('').addHandler(console)
    ##
    # Try to detect native resolution to set the max video resolution to use:
    natwidth, natheight = 0, 0
    logging.debug("Trying to detect native resolution...")
    try:
        import gi
    except:
        logging.debug("Exception importing gi library")
    else:
        try:
            gi.require_version('Gdk', '3.0')
            from gi.repository import Gdk
            w = Gdk.get_default_root_window()
            natwidth, natheight = w.get_geometry()[2:4]
            if not natwidth or not natheight:
                logging.debug("Detected resolution from gi is zero or None")
        except:
            logging.debug("Exception getting resolution with gi library")
        del gi
    if args.maxwidth is None:
        if not natwidth:
            # default fallback width:
            maxwidth = 1280
        else:
            maxwidth = natwidth
    else:
        maxwidth = args.maxwidth
    if args.maxheight is None:
        if not natheight:
            # default fallback height:
            maxheight = 720
        else:
            maxheight = natheight
    else:
        maxheight = args.maxheight
    logging.info('Maximum video resolution allowed: %s x %s' % (maxwidth, maxheight))
    # Check running processes for another instances:
    pslist = subprocess.check_output(shlex.split("ps -ax")).decode("utf-8")
    runcmd = re.findall('.*ytdash.*', pslist)
    if len(runcmd) > 1:
        for instancecmd in runcmd:
            pscolumns = instancecmd.split()
            ppid = pscolumns[0]
            if re.match('^[0-9]+$', ppid):
                pid = int(ppid)
                if thispid != pid:
                    cmdopts = re.findall('ytdash.*', instancecmd)
                    if args.kill:
                        if pscolumns[5] == __file__:
                            killed = 0
                            for signal in (15,) * 5:
                                try:
                                    os.killpg(pid, signal)
                                    time.sleep(0.1)
                                except ProcessLookupError:
                                    logging.info("Instance pid: " +
                                                 ppid + ' was terminated.')
                                    killed = 1
                                    break
                            if not killed:
                                logging.info('Other running instances ' +
                                             'couldn\'t be killed, please do' +
                                             ' it manually.')
                                quit()
                        else:
                            logging.info('The process pid: ' + ppid + ' has the'
                                         ' the same name but different path.' +
                                         ' Not killing it.')
                    else:
                        if cmdopts:
                            if args.onlyone:
                                logging.info('Other instance(s) already ' +
                                             'running, close them manually or' +
                                             ' enable -kill option')
                                quit()
                            elif re.match('.* (-oo|-onlyone).*', cmdopts[0]):
                                logging.info('Other instance(s) already ' +
                                             'running with one-instance mode ' +
                                             'enabled.')
                                quit()
                        else:
                            logging.info('Cannot get cmd options of other' +
                                         '(s) currently running instance(s)')
            else:
                logging.info('Cannot find pid of currently running ' +
                             'instances to terminate them, running anyway.')
    if (args.search or args.research) and args.playlist:
        logging.info('Search mode together with playlist mode will only ' +
                     'search in Youtube for videos if channel IDs ' +
                     'found in given file/s, other normal video ids/urls ' +
                     'found will be played following -nonlive flag option.')
    playerbaseargs = ''
    if args.player[:3] == 'mpv':
        playerbaseargs = ' --input-terminal=no '
        #              ' --rebase-start-time=yes'
        #              '--profile=low-latency'
        if args.volnor:
            playerbaseargs += ' --af lavfi="[alimiter=limit=0.1:level=enabled]"'
        if args.fullscreen:
            playerbaseargs += ' --fullscreen '
        if not args.debug:
            playerbaseargs += ' --really-quiet=yes '
    elif args.player[:3] == 'vlc':
        playerbaseargs = ' --file-caching=5000 '
        if args.fullscreen:
            playerbaseargs += ' --fullscreen '
    else:
        # Other players way to play audio and video separately is unknown so:
        if args.nonlive:
            logging.info('Non-live videos cannot be played with this player.' +
                         ' Please use mpv (recommended) or vlc.')
            quit()
        if args.player[:6] == 'ffplay':
            playerbaseargs = ' -infbuf -framedrop -sync audio '
    logging.debug('Player\'s basic command line: ' + args.player +
                  playerbaseargs)
    # CURL Session:
    session = pycurl.CurlShare()
    session.setopt(pycurl.SH_SHARE, pycurl.LOCK_DATA_COOKIE)
    session.setopt(pycurl.SH_SHARE, pycurl.LOCK_DATA_DNS)
    session.setopt(pycurl.SH_SHARE, pycurl.LOCK_DATA_SSL_SESSION)
    # session.setopt(pycurl.SH_SHARE, pycurl.LOCK_DATA_CONNECT)
    segcurlobjs = []
    for sid in range(3):
        mediaobjs = []
        for mid in range(2):
            curlobj = pycurl.Curl()
            curlobj.setopt(pycurl.SHARE, session)
            curlobj.setopt(pycurl.USERAGENT, pycurl.version + ' YTdash/0.19')
            curlobj.setopt(pycurl.VERBOSE, 0)
            curlobj.setopt(pycurl.CONNECTTIMEOUT, 10)
            curlobj.setopt(pycurl.TIMEOUT, 30)
            # curlobj.setopt(pycurl.TRANSFER_ENCODING, 1)
            # curlobj.setopt_string(CURLOPT_TCP_FASTOPEN, "1L")
            # curlobj.setopt(pycurl.RETURN_TRANSFER, True)
            curlobj.setopt(pycurl.TCP_KEEPALIVE, 1)
            # curlobj.setopt(pycurl.TCP_KEEPIDLE, 15)
            # curlobj.setopt(pycurl.TCP_KEEPINTVL, 15)
            curlobj.setopt(pycurl.PIPEWAIT, 1)
            curlobj.setopt(pycurl.BUFFERSIZE, 524288)
            curlobj.setopt(pycurl.NOSIGNAL, 1)
            # curlobj.setopt(pycurl.HEADER, 0)
            # curlobj.setopt(pycurl.KEEP_SENDING_ON_ERROR, 1)
            curlobj.setopt(pycurl.FOLLOWLOCATION, 1)
            curlobj.setopt(pycurl.CAINFO, certifi.where())
            mediaobjs.append(curlobj)
        segcurlobjs.append(mediaobjs)
    curl = segcurlobjs[0][0]
    defsegoffset = 3  # youtube's default segments offset.
    init = None
    ffmpegbase = None
    player = None
    videodata = None
    vid = 0
    aid = 0
    ffmpegmuxer = None
    BandwidthsAvgs = [0, 1, 2, 3]
    # (X11; Linux x86_64)
    if args.playlist:
        toturls = list()
        for playlist in args.urls:
            if not os.path.isfile(playlist):
                logging.info('File ' + playlist + ' not found.')
                continue
            try:
                with open(playlist, 'r') as fd:
                    fileurls = fd.read().splitlines()
                    logging.debug("fileurls " + str(fileurls))
            except UnicodeDecodeError:
                logging.info('Invalid content on given file, skipping...')
            except FileNotFoundError as ferror:
                logging.info('No such file or directory: ' + playlist)
            else:
                if fileurls:
                    toturls += fileurls
        if not toturls:
            logging.info('0 URLs found.')
            quit()
        else:
            urls = toturls
    else:
        urls = args.urls
    # for urlid in range(len(urls)):
    while len(urls):
        playerargs = playerbaseargs
        url = urlparse(urls[0])
        urlquery = url.query
        if url.fragment and args.playlist:
            print('Playlist track title:' + url.fragment)
            del urls[0]
            continue
        urlstartime = parse_qs(url.query).get('t', [''])[0]
        if urlstartime and urlstartime[-1:] != 's':
            urlstartime += 's'
        urlhost = url.hostname
        urlfolders = url.path.split('/')
        idre = re.compile('^[/]*[A-z0-9_-]{11}$')
        videoid = None
        channelid = None
        userid = None
        if sys.stdout.isatty():
            columns = os.get_terminal_size().columns
        else:
            columns = 80
        # If given string is not a video id, check if search mode is enabled:
        if urlhost:
            if url.hostname[-8:] == "youtu.be":
                videoid = urlfolders[1]
            elif url.hostname[-11:] == "youtube.com":
                if url.path == '/watch':
                    videoid = parse_qs(url.query).get('v', [0])[0]
                elif url.path == '/embed':
                    videoid = urlfolders[2]
                elif url.path[0:8] == '/channel':
                    channelid = urlfolders[2]
                elif url.path[0:5] == '/user':
                    userid = urlfolders[2]
                if channelid or userid:
                    if not args.search and not args.research:
                        logging.info('Channel URL given but search ' +
                                     'disabled, enable search mode to' +
                                     ' list videos found in it or use '
                                     ' directly a video url or id instead.')
                        del urls[0]
                        continue
        # Check if can be the pure video id if search disabled, else skip it.
        elif (not args.search and not args.research) or args.playlist:
            if url.path and re.match(idre, url.path):
                videoid = url.path
            else:
                logging.info('Could not find a video or channel id' +
                             ' in the given string')
                del urls[0]
                continue
        # If the url given does not have a youtube ID is a search query:
        if videoid:
            if args.search or args.research:
                logging.debug('Video URL given, search not needed.')
            # apitype = 'videos'
        else:
            curl.setopt(pycurl.HTTPHEADER, ['Referer:www.youtube.com/test'])
            apibaseurl = 'https://www.googleapis.com/youtube/v3/'
            apipar = {}
            apipar['part'] = 'snippet'
            apipar['key'] = 'AIzaSyBSnNQ7qOmLPxC5CaHH9BWHqAgrecwzCVA'
            apiurlchecklive = apibaseurl + 'videos?' + urlencode(apipar)
            if userid:
                apitype = 'channels'
                apipar['forUsername'] = userid
                apiurl = apibaseurl + apitype + '?' + urlencode(apipar)
                logging.debug("API URL: " + apiurl)
                useritems = download(curl, apiurl, 0, 0, 0, 1)
                logging.debug('Channel items: ' + str(useritems))
                try:
                    useritems = eval(useritems)
                except:
                    logging.info('Error getting API response content.')
                if type(useritems) is not dict:
                    useritems = {}
                channelitems = useritems.get('items')
                if (channelitems and len(channelitems) > 0 and
                   channelitems[0].get('id')):
                    channelid = channelitems[0].get('id')
                else:
                    logging.info('Could not obtain a channel id from user id')
                    del urls[0]
                    continue
                del apipar['forUsername']
            apitype = 'search'
            apipar['type'] = 'video'
            apipar['order'] = args.sortby
            if not args.nonlive:
                apipar['eventType'] = eventype = args.eventtype
            else:
                eventype = 'Nonlive'
            apipar['videoDimension'] = '2d'
            # apipar['regionCode'] = 'AR'
            apipar['safeSearch'] = args.safesearch
            apipar['videoDuration'] = args.duration
            apipar['videoType'] = args.videotype
            apipar['type'] = args.type
            apipar['videoLicense'] = args.license
            apipar['videoDefinition'] = args.definition  # high|any
            apipar['maxResults'] = args.maxresults
            apipar['videoEmbeddable'] = 'true'
            apipar['videoSyndicated'] = 'true'
            # Create the name of cache file:
            cachefilename = (apipar['type'] +
                             '+' + apipar['videoType'] +
                             '+' + eventype +
                             '+' + str(apipar['maxResults']) +
                             '+' + apipar['videoDuration'] +
                             '+' + apipar['videoDefinition'] +
                             '+' + apipar['safeSearch'] +
                             '+' + apipar['videoLicense'] +
                             '+' + str(apipar['order']) + '+')
            if channelid:
                apipar['channelId'] = channelid
                cachefilename += channelid
            else:
                apipar['q'] = urls[0].replace('/', '')
                cachefilename += apipar['q']
            # Full name with relative filename limited below native max length:
            searchcachefile = cachedir + cachefilename[0:200] + '.cache'
            apipar['fields'] = ('items(id,snippet/title,snippet/' +
                                'channelTitle,snippet/description,' +
                                'snippet/liveBroadcastContent)')
            apiurl = apibaseurl + apitype + '?' + urlencode(apipar)
            # Check if cached search query version if less than 1 day old:
            if not os.path.isfile(searchcachefile):
                research = 1
                cachedjson = 0
            else:
                logging.debug('Search query is in cache.')
                modtime = os.path.getmtime(searchcachefile)
                lifetime = (time.time() - modtime) / 3600
                try:
                    with open(searchcachefile, 'r') as fd:
                        cachedcontent = fd.readlines()[0]
                    cachedjson = eval(cachedcontent)
                except:
                    invalidcontent = 1
                else:
                    invalidcontent = 0
                    if lifetime > 24 or args.research:
                        research = 1
                    elif(type(cachedjson) is not dict or
                         len(cachedcontent) < 10 or
                         cachedcontent[:9] != "{'items':"):
                            invalidcontent = 1
                    else:
                        logging.info('Search query is cached, using it.')
                        research = 0
                if invalidcontent:
                    logging.debug('Invalid cached content, researching...')
                    research = 1
                    cachedjson = 0
            # perform the API request if search query isn't cached or too old:
            if research:
                logging.debug("API URL: " + apiurl)
                apires = download(curl, apiurl, 0, 0, 0, 1)
                rjson = {}
                if apires:
                    try:
                        rjson = eval(apires)
                    except:
                        logging.info('Error parsing API response.')
                    else:
                        del apires
                        if type(rjson) is not dict:
                            rjson = {}
                    logging.debug('Rjson: ' + str(rjson))
                    if rjson.get('error'):
                        reason = rjson['error']['errors'][0]['reason']
                        message = rjson['error']['errors'][0]['message']
                        logging.info('API failure reason: ' + reason)
                        logging.info('API message: ' + message)
                        rjson = {}
                    elif rjson:
                        with open(searchcachefile, 'w') as fd:
                            fd.write(str(rjson))
                if not rjson and cachedjson:
                        research = 0
                        rjson = cachedjson
                        logging.info('Error getting API results, using ' +
                                     'old cached version.')
            else:
                rjson = cachedjson
            curl.setopt(pycurl.HTTPHEADER, None)
            items = rjson.get('items')
            if items:
                print("Videos found:")
            else:
                messa="No videos found for \"%s\"." % urls[0]
                print(messa)
                notify_send(messa, 5000)
                del urls[0]
                continue
            itemnum = 1
            videoids = []
            for item in items:
                snippet = item['snippet']
                title = snippet['title'].replace('"', "\'")[:columns - 4:]
                videoids.append('//youtu.be/' + item['id']['videoId'])
                channeltitle = snippet["channelTitle"]
                description = snippet['description'][:columns - 24:] + '...'
                livebroad = snippet['liveBroadcastContent']
                if livebroad == 'none':
                    livebroad = False
                else:
                    livebroad = True
                # html.unescape(title)
                print('%s) %s\n' % (itemnum, html.unescape(title)) +
                      '    * Description: {}\n'.format(repr(description)) +
                      '    * Channel: %s\n' % channeltitle +
                      '    * Live: %s' % livebroad)
                itemnum += 1
            print('Enter the number(s) of the video(s) to play, separated by ' +
                  'commas, in the order you want (i.e: 2,6,1,4), press '
                  'Enter to play\'em all in current order, "n" to skip this' +
                  ' search or "q" to exit.')
            nextquery = 0
            while True:
                videosidssel = []
                if not args.autoplay:
                    answer = input().split(',')
                else:
                    answer = ['']
                if len(answer) == 1 and not answer[0]:
                    videosidssel = videoids
                else:
                    for itemnum in answer:
                        if itemnum == 'n' or itemnum == 'N':
                            nextquery = 1
                            break
                        elif itemnum == 'q' or itemnum == 'Q':
                            quit()
                        elif(re.match(r'^[0-9]+$', itemnum) and
                             int(itemnum[:1]) and int(itemnum) <= len(items)):
                                videosidssel.append(videoids[int(itemnum) - 1])
                        else:
                            print('Invalid input, only integers from 1' +
                                  ' to ' + str(len(items)) +
                                  ' separated by commas, "n" or "q" are' +
                                  ' allowed.')
                            break
                logging.debug('Video IDs chosen: ' + str(videosidssel))
                if len(videosidssel) >= len(answer):
                    del urls[0]
                    urls = videosidssel + urls
                    videoid = urls[0]
                    break
                elif nextquery:
                    break
            if nextquery:
                del urls[0]
                continue
        logging.info('#'*min(columns, 80))
        videoid = videoid[-11:]
        logging.info('Fetching data for Video ID: %s' % videoid)
        # Get video metada:
        mediadata = get_mediadata(curl, videoid)
        if type(mediadata) is int:
            if mediadata == 1:
                logging.debug('The video doesn\'t met search criteria.')
            elif mediadata == 2:
                logging.info('Unable to get all the video metadata needed.')
            del urls[0]
            # Sleep between many failed fast request:
            time.sleep(1)
            continue
        else:
            latencyclass = mediadata[0]
            audiodata = mediadata[1]
            videodata = mediadata[2]
            buffersecs = mediadata[3]
            earliestseqnum = mediadata[4]
            startnumber = mediadata[5]
            metadata = mediadata[6]
            segsecs = mediadata[7]
            periodstarttime = metadata.get('start')
            segmentsnumber = metadata.get('segmentsnumber')
            title = metadata.get('title', '').replace('"', "\'")
            description = metadata.get('shortDescription', '').replace('"',
                                                                       "\'")
            author = metadata.get('author')
            private = metadata['isPrivate']
            lengthsecs = metadata['lengthSeconds']
            postlivedvr = metadata.get('isPostLiveDvr')
            livecontent = metadata.get('isLiveContent')  # media is/was live
            live = metadata.get('isLive', False)
            lowlatency = metadata.get('isLowLatencyLiveStream')
            livedvr = metadata.get('isLiveDvrEnabled')
            otf = metadata.get('Otf')
            manifesturl = metadata.get('ManifestUrl')
            viewcount = metadata.get('viewCount')
        # Disable manifested OTF, use the non otf, the adpativefmts urls:
        if otf:
            otf = 0
            manifesturl = 0
        asegoffset = vsegoffset = remainsegms = defsegoffset
        minsegms = 2
        maxsegms = 2
        if args.preferquality:
            downresist = 1.5  # Higher means more delay detected to switch down
            upresist = 1  # Higher means more bandwidth needed to switch up
        else:
            downresist = 1.3
            upresist = 1.3
        if live:
            if latencyclass[0] == 'ULTRA_LOW':
                segsecs = 1
                maxsegms = 2
            elif latencyclass[0] == 'LOW':
                segsecs = 2
            elif latencyclass[0] == 'NORMAL':
                segsecs = 5
                minsegms = 1
                maxsegms = 1
                downresist = 1.1
            if args.reallive:
                remainsegms = vsegoffset = 0
        maxaid = len(audiodata) - 1
        maxvid = len(videodata) - 1
        analyzedur = 1000000
        # Player max cache in secs
        cachesecs = 60
        # max player backbuffer to conserve, in Mb
        backcachesize = 50 * 1048576
        # max player backbuffer to conserve, in Mb
        cachesize = 50 * 1048576
        # Default terminal logging printing info:
        if live or postlivedvr:
            if args.fixed:
                aid = maxaid
                vid = maxvid
            else:
                aid = min(args.audioquality, maxaid)
                vid = int(maxvid/2)
            inita = initv = 1
            minvid = 0
            # Limit backbuffer to youtube's max default in seconds (12h) or use
            # the number of already generated segments if below back buffer
            # manifest's limit (timeShiftBufferDepth) or if is a postlivedvr.
            # The backbuffer in live streams can be above manifest's max
            # (but always below YouTube max limit), but for postlivedvr
            # (and otf's?) the max is the manifest's one:
            if not periodstarttime or postlivedvr:
                maxbackbuffersecs = segmentsnumber*segsecs
            else:
                maxbackbuffersecs = min(periodstarttime+buffersecs, 43200)
            # Limit of segment number to force resync :
            segmresynclimit = 43200/segsecs
            headnumber = len(audiodata[1][2]) + earliestseqnum
            fromzero = 0
            forcedlive = 0
            if startnumber > earliestseqnum:
                # This are forced live streams (without pause button, no offset)
                forcedlive = 1
                segmresynclimit = startnumber - earliestseqnum
                cachesecs = segmresynclimit * segsecs
                backcachesize = 0
                maxbackbuffersecs = segsecs * defsegoffset
            elif args.offset or postlivedvr:
                if postlivedvr:
                    offsetnum, offsetunit = 12, "h"
                else:
                    # This is for live streams with backbuffer available:
                    offsetnum = int(args.offset[0:-1])
                    offsetunit = args.offset[-1]
                if offsetunit == "h":
                    secs = 3600
                elif offsetunit == "m":
                    secs = 60
                elif offsetunit == "s":
                    secs = 1
                # Filter time to the max allowed:
                offsetsecs = min(maxbackbuffersecs, offsetnum*secs)
                vsegoffset = asegoffset = int(offsetsecs/segsecs)
                if offsetsecs < offsetnum*secs:
                    if not startnumber:
                        fromzero = 1
                    logging.info('Maximum time offset available is ' +
                                 str(int(maxbackbuffersecs/secs)) +
                                 ', playing from there...')
                # vsegoffset = min(segmresynclimit, vsegoffset, headnumber)
            arraydelayslim = min(max(vsegoffset, 1), defsegoffset)
            seqnumber = int(headnumber - vsegoffset)
        else:
            apipe = 0
            vid = int(len(videodata) / 1) - 1
            aid = min(args.audioquality, maxaid)
            minvid = 2
            headnumber = 999
            seqnumber = 0
            remainsegms = 0
            segmresynclimit = 99999
            arraydelayslim = 1
            selectedbandwidth = [0, 0]
            nextbandwidth = [0, 0]
            minbandavg = [0, 0]
            minbandlast = [0, 0]
            bandslastavg = [0, 0]
            bandwidthdown = 1
            bandwidthup = 1
            if otf:
                vsegoffset = len(videodata[2][1]) - 1
                asegoffset = len(audiodata[2][2]) - 1
                logging.debug('Audio segment offset n: %s' % asegoffset)
                initaurl = audiodata[aid][1].text
                initaurl += audiodata[aid][2][0].get('sourceURL')
                initvurl = videodata[vid][0].text
                initvurl += videodata[vid][1][0].get('sourceURL')
                curl.setopt(pycurl.URL, initvurl)
                initv = curl.perform_rb()
                curl.setopt(pycurl.URL, initaurl)
                inita = curl.perform_rb()
                logging.debug("Media IDs: %s %s" % (aid, vid))
                logging.debug("Audio Main URL: %s" % initaurl)
                logging.debug("Video Main URL: %s" % initvurl)
            logging.debug('Video segment offset n: %s' % vsegoffset)
        # General Logging infos:
        logging.info('Views count: ' + viewcount)
        logging.info("Is live: %s" % live)
        if live:
            logging.debug("Audio Main URL: %s" % audiodata[aid][1].text)
            logging.debug("Video Main URL: %s" % videodata[vid][0].text)
            livemode = ''
            if forcedlive:
                livemode += 'FORCED '
                # logging.info('Time offsets are disabled for this video.')
            livemode += latencyclass[0].replace('_', ' ') + ' LATENCY'
            logging.info('Live mode: %s' % livemode)
        logging.info('* Title: %s' % title)
        logging.info('* Author: %s' % author)
        logging.info('#'*min(columns, 80))
        notify_send("Author: " + author, 5000, title)
        if not args.nodescription and description:
            logging.info('* Description: \n%s' % description)
        logging.debug("Segment duration in secs: " + str(segsecs))
        logging.debug("Back buffer depth in secs: " + str(buffersecs))
        logging.debug("Earliest seq number: " + str(earliestseqnum))
        logging.debug('Head Number: %s, ' % headnumber +
                      'Start Number: %s, ' % startnumber)
        # While End ---
        if manifesturl:
            ffbaseargs = args.ffmpeg + ' -v %s ' % ffloglevel
            ffbaseinputs = ' -thread_queue_size 500 -flags +low_delay '
            ffbaseargs += ' -analyzeduration ' + str(analyzedur)
            if otf:
                apipe = os.pipe()
                fda = os.fdopen(apipe[1], 'wb', 1048576)
                ffbaseargs += ffbaseinputs + ' -i pipe:%s ' % apipe[0]
                fffds = (apipe[0],)
            else:
                fffds = ()
            ffbaseargs += ffbaseinputs + ' -i pipe:0 '
            ffbaseargs += ' -c copy -f nut '
            ffbaseargs += ' -bsf:v h264_mp4toannexb '
            ffbaseargs += ' -flags +low_delay pipe:1'
            ffmpegbase = subprocess.Popen(shlex.split(ffbaseargs),
                                          stdin=subprocess.PIPE,
                                          stdout=subprocess.PIPE,
                                          bufsize=-1,
                                          pass_fds=fffds)
            playerstdin = ffmpegbase.stdout
            ffmuxerstdout = ffmpegbase.stdin
            playerargs += ' - '
            playerfds = ()
            if ffmpegbase.poll() is not None:
                logging.info('Error openning main ffmpeg, quitting...')
                quit()
        else:
            apipe = os.pipe()
            vpipe = os.pipe()
            playerargs += ' fd://%s ' % vpipe[0]
            if args.player[:3] == 'mpv':
                # playerargs += '--audio-file=%s ' % audiodata[aid]['url']
                playerargs += ' --audio-file=fd://%s ' % apipe[0]
            elif args.player[:3] == 'vlc':
                # playerargs += '--input-slave="%s"' % audiodata[aid]['url']
                playerargs += ' --input-slave=fd://%s ' % apipe[0]
            # playerargs += ' "%s" ' % videodata[vid]['url']
            playerstdin = None
            playerfds = (apipe[0], vpipe[0])
            # playerfds = ()
            ffmpegbase = None
            ffmpegmuxer = None
            ffmuxerstdout = None
        if args.player == 'mpv':
            playerargs += (' --title="%s" ' % (title + " - " + author) +
                           '--osd-font-size=%s ' % 25 +
                           '--osd-align-x=center ' +
                           '--demuxer-max-bytes=%s ' % cachesize +
                           '--demuxer-seekable-cache=yes ' +
                           '--keep-open ')
            if not args.nodescription and description:
                playerargs += (' --osd-playing-msg="%s" ' %
                               description.replace('\\', "") +
                               '--osd-duration=%s ' %
                               min(len(description) * 25, 10000))
            if urlstartime:
                offsetnum, offsetunit = urlstartime[0:-1], urlstartime[-1]
                offsetsecs = int(offsetnum)
                if offsetunit == 'm':
                    offsetsecs *= 60
                elif offsetunit == 'h':
                    offsetsecs *= 3600
                playerargs += ' --start=%s ' % offsetsecs
            if manifesturl:
                playerargs += ('--cache-secs=%s ' % cachesecs +
                               '--demuxer-max-back-bytes=%s ' % backcachesize +
                               '--demuxer-max-bytes=%s ' % cachesize)
        elif args.player == 'vlc':
            playerargs += (' --input-title-format "%s" ' % (title + " - " +
                                                            author) +
                           '--no-video-title-show ')
        playercmd = args.player + playerargs
        logging.debug('Player command line args: ' + playercmd)
        player = subprocess.Popen(shlex.split(playercmd),
                                  # env=env,
                                  bufsize=-1,
                                  shell=False,
                                  stdin=playerstdin,
                                  stdout=None,
                                  stderr=None,
                                  pass_fds=playerfds)
        playertries = 0
        while player.poll() is not None:
            logging.debug("Waiting media player availability...")
            if playertries < 5:
                time.sleep(1)
            else:
                logging.info('Could not open the player, check args...')
                quit()
            playertries += 1
        if ffmuxerstdout == "player":
            ffmuxerstdout = player.stdin
        elif ffmpegbase and ffmpegbase.poll() is None:
            ffmpegbase.stdout.close()
        # MAIN LOOP: ------------------------------------------------------#
        audioband = round(int(audiodata[aid].get('bandwidth', 0))/8/1024)
        delaytogoup = max(round(segsecs/2, 3), 1)
        numsegmsecs = int(60/segsecs)  # N of segments that fit in X secs.
        snumsegmsecs = int(30/segsecs)  # Shorter N segments that fit in X sec.
        delays = []
        truedelays = []
        headnumbers = []
        basedelays = []
        # headtimes = []
        # walltimemss = []
        bandest = []
        bandest2 = []
        bandest3 = []
        basedelayavg = cachecontrol = aend = vend = playerclosed = mindelay = 0
        down = 0
        segms = firstrun = 1
        http_errors = youtubeissues = ended = end = False
        pool = ThreadPoolExecutor(max_workers=2*defsegoffset)
        while True:
            starttime = time.time()
            if sys.stdout.isatty():
                columns = os.get_terminal_size().columns
            try:
                # sequencenums = []
                segmsresults = []
                rpipes = []
                logging.debug('Sequence Number: %s, ' % seqnumber +
                              'Remaining segments: %s' % remainsegms)
                if firstrun:
                    numbsegms = 1
                else:
                    numbsegms = min(max(remainsegms, minsegms), maxsegms)
                # Media downloads imapping:
                for sid in range(numbsegms):
                    if not manifesturl:
                        pipebuffer = 524288  # Same or less than maxbytes
                        segsecs = 5
                        amainurl = audiodata[aid]['url']
                        vmainurl = videodata[vid]['url']
                        vsegurl = asegurl = ''
                        rpipes = (apipe, vpipe)
                        fda = os.fdopen(apipe[1], 'wb', pipebuffer)
                        initv = inita = 0
                    else:
                        pipebuffer = 1024
                        if initv and inita:
                            if live:
                                asegurl = vsegurl = ''
                        if not otf:
                            apipe = os.pipe()
                            rpipes.append([apipe[0]])
                            fda = os.fdopen(apipe[1], 'wb', pipebuffer)
                        else:
                            rpipes.append([0])
                        vpipe = os.pipe()
                        rpipes[sid].append(vpipe[0])
                        amainurl = audiodata[aid][1].text
                        # logging.debug("Audio Main URL: %s" %
                        #               audiodata[aid][1].text)
                        vmainurl = videodata[vid][0].text
                        if postlivedvr or otf:
                            if asegoffset:
                                asegurl = audiodata[aid][-1][-asegoffset]
                                asegurl = asegurl.get('media')
                            else:
                                aend = 1
                            if vsegoffset:
                                vsegurl = videodata[vid][1][-vsegoffset]
                                vsegurl = vsegurl.get('media')
                            else:
                                vend = 1
                            if otf or not initv == 1 == inita:
                                if not vend:
                                    vsegoffset -= 1
                                if not aend:
                                    asegoffset -= 1
                                seqnumber += 1
                            if aend and vend:
                                raise Endit
                        elif live and initv == 0 == inita:
                            asegurl = vsegurl = "sq/%s" % seqnumber
                            seqnumber += 1
                    # logging.debug('Audio segment URL: %s' % str(asegurl))
                    # logging.debug('Video segment URL: %s' % str(vsegurl))
                    fdv = os.fdopen(vpipe[1], 'wb', pipebuffer)
                    ares = pool.submit(get_media, [amainurl, asegurl,
                                       fda, segcurlobjs[sid][0],
                                       inita])
                    vres = pool.submit(get_media, [vmainurl, vsegurl,
                                       fdv, segcurlobjs[sid][1],
                                       initv])
                    segmsresults.append((ares, vres))
                pid = error = 0
                for segmresult in segmsresults:
                    ffmuxerstarttimer = time.time()
                    if ffmpegmuxer is not None:
                        logging.debug('Waiting ffmpeg muxer...')
                        # Check if player was closed while waiting muxer:
                        rounds = paused = 0
                        while True:
                            try:
                                ffmpegmuxer.communicate(timeout=1)
                                '''if paused:
                                    # segcurlobjs[pid][0].pause(0)
                                    # segcurlobjs[pid][1].pause(0)
                                    logging.debug('Download unpaused.')
                                    paused = 0'''
                                break
                            except subprocess.TimeoutExpired:
                                '''if rounds == 5:
                                    if not paused:
                                        paused = 1
                                    logging.debug('Download paused.')
                                    # segcurlobjs[pid][0].pause(1)
                                    # segcurlobjs[pid][1].pause(1)
                                rounds += 1'''
                                logging.debug('Checking player...')
                                if player.poll() is not None:
                                    playerclosed = 1
                                    break
                    ffmuxerdelay = round(time.time() - ffmuxerstarttimer, 4)
                    if (not playerclosed and manifesturl and
                       not inita == initv == 1):
                        logging.debug('FFmpeg read pipes: %s, %s' %
                                      (rpipes[pid][0], rpipes[pid][1]))
                        ffmpegmuxer = ffmuxer(args.ffmpeg, ffmuxerstdout,
                                              rpipes[pid][0],
                                              rpipes[pid][1])
                    for mediares in segmresult:
                        while True:
                            try:
                                result = mediares.result(timeout=1)
                                break
                            except TimeoutError:
                                logging.debug('Waiting download to complete...')
                                if player.poll() is not None:
                                    mediares.cancel()
                                    result = 1
                                    break
                        if type(result) is tuple:
                            (status, basedelay, headnumber,
                             headtimems, sequencenum, walltimems,
                             segmentlmt, contentlength, cachecontrol,
                             bandwidths, speed, contenttype, newurl,
                             err) = result
                            if headnumber:
                                headnumbers.append(int(headnumber))
                            # if headtimems:
                            #     headtimes.append(int(headtimems))
                            # if walltimems:
                            #     walltimemss.append(int(walltimems))
                            if bandwidths:
                                # Append each bandwidth type to its list:
                                bandest.append(bandwidths[1])
                                bandest2.append(bandwidths[2])
                                bandest3.append(bandwidths[3])
                            if status == 200 or status == 206:
                                if contenttype == "video/mp4":
                                    if newurl is not None:
                                        if not manifesturl:
                                            videodata[vid]['url'] = newurl
                                        else:
                                            videodata[vid][0].text = newurl
                                elif contenttype == "audio/mp4":
                                    if newurl is not None:
                                        if not manifesturl:
                                            audiodata[aid]['url'] = newurl
                                        else:
                                            audiodata[aid][1].text = newurl
                                if basedelay:
                                    basedelays.append(basedelay)
                                # if sequencenum:
                                #    sequencenums.append(sequencenum)
                            if err:
                                error = 1
                        elif result == 1:
                            end = True
                        elif result == 2:
                            http_errors = True
                        elif result == 3:
                            youtubeissues = True
                        elif result == 4:
                            ended = True
                    if otf or manifesturl:
                        closepipes(rpipes[pid])
                        pid += 1
                # Check for errors in For results: ----------------------------#
                if http_errors:
                    message = 'Too many errors in a row, aborting.'
                elif youtubeissues:
                    message = 'YouTube\'s server issues, aborting.'
                elif ended:
                    message = 'Live event has ended.'
                else:
                    message = 0
                if end or ended or http_errors or youtubeissues:
                    print(' ' * columns, end='\r')
                    if message:
                        logging.info(message)
                        notify_send(message, 10000, title)
                    raise Endit
                # Limit Arrays
                # headtimes = headtimes[-numsegmsecs:]
                # walltimemss = walltimemss[-numsegmsecs:]
                headnumbers = headnumbers[-numsegmsecs:]
                basedelays = basedelays[-arraydelayslim * 2:]
                if headnumbers:
                    headnumber = max(headnumbers)
                    if not firstrun:
                        remainsegms = max(headnumber - seqnumber, 0)
                    elif fromzero:
                        seqnumber = 0
                        fromzero = 0
                    else:
                        seqnumber = headnumber - vsegoffset
                        logging.debug('First Segment Offset: %s' % vsegoffset)
                # Check links expiring time(secs remaining):
                if cachecontrol:
                    expiresecs = re.search('private, max-age=(.*)',
                                           cachecontrol)
                    if expiresecs:
                        expiresecs = int(expiresecs.group(1))
                        logging.debug('URLs expire in %s seconds' % expiresecs)
                    if expiresecs is not None and expiresecs <= 20:
                        logging.debug('URL Expired %s, refreshing metadata...'
                                      % expiresecs)
                        mediadata = get_mediadata(pycurl.Curl(), videoid)
                        if mediadata == 1 or mediadata == 2:
                            raise Endit
                        else:
                            segsecs = mediadata[7]
                            audiodata = mediadata[1]
                            videodata = mediadata[2]
                # Resyncing:
                if remainsegms > segmresynclimit:
                    seqnumber = headnumber - vsegoffset
                    print(' ' * columns, end='\r')
                    logging.info('Resyncing...')
                firstrun = 0
                # DELAYS: -----------------------------------------------------#
                if live or postlivedvr:
                    segms = len(segmsresults)
                if not error:
                    # Save total time that took to download all segment(s):
                    delay = round((time.time()-starttime-ffmuxerdelay)/segms, 4)
                    delays.append(round(delay, 4))
                    delays = delays[-arraydelayslim:]
                    delayavg = round(sum(delays) / len(delays), 2)
                    if len(basedelays) > 1 and delays:
                        basedelayavg = round(sum(basedelays) / (
                                             2 * len(basedelays)), 4)
                        mindelay = min(min(basedelays) / 2, mindelay)
                        truedelay = round(delays[-1]-(max(basedelays[-2:])/2),
                                          3)
                        truedelays.append(truedelay)
                        truedelays = truedelays[-arraydelayslim:]
                        truedelayavg = round(sum(truedelays)/len(truedelays), 3)
                        # Min latency check:
                        if mindelay > segsecs * 0.75:
                            logging.info('Latency to high: %s seconds, ' %
                                         mindelay + 'playback not realistic')
                    threadsc = active_threads()
                    logging.debug("--> DELAY TO UP: %s seconds\n" %
                                  delaytogoup +
                                  "--> BASEDELAYS: %s seconds\n" % basedelays +
                                  "--> BASEDELAY AVG: %s seconds\n" %
                                  basedelayavg +
                                  "--> MIN DELAY: %s seconds\n" % mindelay +
                                  "--> DELAYS: %s" % delays +
                                  "--> DELAY AVG: %s seconds\n" % delayavg +
                                  "--> FFMPEG DELAYS: %s\n" % ffmuxerdelay +
                                  "--> Threads Count: %s\n" % threadsc)
                logging.debug('Curl error: ' + str(error))
                # BANDWIDTHS: -------------------------------------------------#
                if not args.fixed and (live or postlivedvr):
                    # Limit bandwidths arrays info to last 25 secs of video :
                    bandest = bandest[-numsegmsecs:]
                    bandests = bandest[-snumsegmsecs:]
                    bandest2 = bandest2[-numsegmsecs:]
                    lastbandest2 = max(bandest2[-segms:])
                    bandest2s = bandest2[-snumsegmsecs:]
                    bandest3 = bandest3[-numsegmsecs:]
                    bandest3s = bandest3[-snumsegmsecs:]
                    # Set bandwidths averages:
                    bandestavg = round(sum(bandest)/len(bandest))
                    bandestsavg = round(sum(bandests)/len(bandests))
                    bandest2avg = round(sum(bandest2)/len(bandest2))
                    bandest2savg = round(sum(bandest2s)/len(bandest2s))
                    bandest3avg = round(sum(bandest3)/len(bandest3))
                    bandest3savg = round(sum(bandest3s)/len(bandest3s))
                    # Get bandwidth needed per close video quality:
                    pvid = max(vid - 1, minvid)
                    nvid = min(vid + 1, len(videodata) - 1)
                    prevvband = int(videodata[pvid].get('bandwidth', 0))/8/1024
                    currvband = int(videodata[vid].get('bandwidth', 0))/8/1024
                    nextvband = int(videodata[nvid].get('bandwidth', 0))/8/1024
                    prevtband = round(prevvband) + audioband
                    currtband = round(currvband) + audioband
                    nexttband = round(nextvband) + audioband
                    logging.debug('Bandsest2: ' + str(bandest2))
                    logging.debug('Bandsest2s: ' + str(bandest2s))
                    if not args.debug:
                        ptext = ('\rEstimated bandwidth Last/Avg: ' +
                                 '%skB/s' % bandest2[-1] +
                                 ' / %skB/s ' % bandest2avg +
                                 '- Delays Last/Avg: %ss / %ss' %
                                 (delays[-1], delayavg))[:columns]
                        print(ptext + (' ' * (columns - len(ptext))), end='\r')
                    logging.debug('X-Bandwidth-Avg: ' + str(bandwidths[0]))
                    logging.debug('X-Bandwidth-Est: ' + str(bandest[-1]) +
                                  ' - AVG: ' + str(bandestavg) + ' - sAVG: ' +
                                  str(bandestsavg))
                    logging.debug('X-Bandwidth-Est2: ' + str(lastbandest2) +
                                  ' - AVG: ' + str(bandest2avg) + ' - sAVG: ' +
                                  str(bandest2savg))
                    logging.debug('X-Bandwidth-Est3: ' + str(bandest3[-1]) +
                                  ' - AVG: ' + str(bandest3avg) + ' - sAVG: ' +
                                  str(bandest3savg))
                    logging.debug('Prev total band: ' + str(prevtband))
                    logging.debug('Curr total band: ' + str(currtband))
                    logging.debug('Next total band: ' + str(nexttband))
                # Select a quality at first run:
                if inita and initv:
                    inita = initv = 0
                    if not args.fixed:
                        # Select an audio and video quality:
                        minband = bandest3avg
                        logging.debug("Bandwidth detected: %s" % bandest3avg)
                        logging.debug('Audio bandwidth: %s' % audioband)
                        for idv in range(len(videodata)):
                            manband = videodata[idv].get('bandwidth', 0)
                            manband = (int(manband)/8/1024) + int(audioband)
                            vid = idv
                            if manband > minband:
                                #  or manband / 8 > maxband * 1024
                                break
                        vid = max(idv - 1, minvid)
                        logging.debug('AID Selected: %s' % aid)
                        logging.debug('VID Selected: %s' % vid)
                # CHECK TO GO DOWN: -------------------------------------------#
                # After down wait ten passes to check to go up (avoid slow avg):
                if down > 0:
                    down -= segms
                if(not args.fixed and vid > minvid and ffmuxerdelay < 1 and
                   not error and basedelayavg < segsecs):
                        gcheck = 1
                else:
                    gcheck = 0
                if gcheck:
                    if (delayavg > segsecs*downresist and
                       delays[-1] > segsecs*downresist):
                        # (delays[-1] > segsecs * 2 or
                        # min(delays) > segsecs+0.3)):
                        down = numsegmsecs
                        print(' ' * columns, end='\r')
                        print('\rDelays detected, lowering video quality...'
                              [0:columns], end='\r')
                        # how much to drop quality considering downresist:
                        inertia = max(int(delays[-1]/(segsecs*downresist)), 1)
                        vid = max(minvid, vid - inertia)
                        if otf:
                            initvurl = videodata[vid][0].text
                            initvurl += videodata[vid][1][0].get('sourceURL')
                            session.setopt(pycurl.URL, initvurl)
                            initv = session.perform_rb()
                            logging.debug('Initurl' + initvurl)
                        log_(("DOWN", vid, remainsegms, mindelay,
                             ffmuxerdelay, delaytogoup, truedelays,
                             truedelayavg, basedelays, basedelayavg, delays,
                             delayavg, currtband, nexttband,
                             videodata[vid][0].text))
                elapsed3 = round(time.time() - starttime, 4)
                logging.debug("---> TOTAL LOCAL DELAY: " + str(elapsed3))
                # CHECK TO GO UP: -----------------------------------------#
                # General check:
                logging.debug('Down Count: ' + str(down))
                if(not args.fixed and vid < maxvid and down < 1 and
                   # ((bandest2[-1] > nexttband * upresist and vid < 3) or
                   bandest2avg > nexttband*upresist and
                   max(bandest2[-segms:]) > nexttband*upresist and
                   basedelayavg < segsecs):
                        gcheck = True
                else:
                    gcheck = False
                logging.debug('GCHECK:' + str(gcheck))
                # Check per live mode type:
                if gcheck:
                    goup = 0
                    if (not lowlatency or postlivedvr or
                       (lowlatency and args.offset)):
                            if(delays[0] and delayavg < delaytogoup and
                               max(delays) < delaytogoup):
                                goup = 1
                    elif lowlatency and not args.offset:
                        for delay in delays:
                            if vid < 1 or round(delay, 2) <= segsecs:
                                delaysok = True
                            else:
                                delaysok = False
                                break
                        '''# delaysok = True
                        logging.debug('Delays Ok: ' + str(delaysok))
                        if ((delaysok and round(delayavg, 2) == segsecs) or
                           ffmuxerdelay > 1):'''
                        if delaysok and delayavg < segsecs:
                            goup = 1
                    if goup:
                        print(' ' * columns, end='\r')
                        print('\rSwitching to higher video quality...'
                              [0:columns], end='\r')
                        vid += 1
                        if otf:
                            initvurl = videodata[vid][0].text
                            initvurl += videodata[vid][1][0].get('sourceURL')
                            session.setopt(pycurl.URL, initvurl)
                            initv = session.perform_rb()
                            logging.debug('Initurl' + initvurl)
                        log_(("UP", vid, remainsegms, mindelay,
                             ffmuxerdelay, delaytogoup, truedelays,
                             truedelayavg, basedelays, basedelayavg, delays,
                             delayavg, currtband, nexttband,
                             videodata[vid][0].text))
                if live:
                    if((not lowlatency and remainsegms <= 0)):
                        # (lowlatency and remainsegms > 10)):
                        sleepsecs = max(round((segsecs) - delays[-1] + 0.100,
                                              4), 0)
                        logging.debug("Sleeping %s seconds..." % sleepsecs)
                        while sleepsecs > 0:
                            if player.poll() is not None:
                                raise Endit
                            partialsecs = min(1, max(round(sleepsecs, 4), 0))
                            sleepsecs -= 1
                            if partialsecs:
                                logging.debug("Waiting %s sec..." % partialsecs)
                                time.sleep(partialsecs)
            # EXCEPTIONS: -----------------------------------------------------#
            except Endit:
                if player.poll() is not None:
                    print(' ' * columns, end='\r')
                    playclosemess = 'Player closed'
                    if len(urls) > 1:
                        playclosemess += ', playing next video...'
                    else:
                        playclosemess += ', no more videos to play.'
                    logging.info(playclosemess)
                else:
                    print(' ' * columns, end='\r')
                    logging.info('Streaming completed, waiting player...')
                    player.communicate()
                    player.wait()
                if playerfds:
                    closepipes(playerfds)
                # This has to be after closing players pipes or it hangs:
                pool.shutdown(wait=True)
                for curlobjs in segcurlobjs:
                    for curlobj in curlobjs:
                        curlobj.setopt(pycurl.NOBODY, 0)
                        curlobj.setopt(pycurl.HEADER, 0)
                        curlobj.setopt(pycurl.WRITEDATA, BytesIO())
                        curlobj.setopt(pycurl.RANGE, None)
                        curlobj.setopt(pycurl.HEADERFUNCTION, BytesIO().write)
                        curl.setopt(pycurl.HEADER, 0)
                if ffmpegbase:
                    ffmpegbase.kill()
                    ffmpegbase.wait()
                if ffmpegmuxer:
                    ffmpegmuxer.kill()
                    ffmpegmuxer.wait()
                break
        # End While -
        del urls[0]
    sys.stdout.flush()
    os.closerange(3, 100)
